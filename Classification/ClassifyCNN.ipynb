{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score,precision_score,accuracy_score,roc_curve\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,TensorDataset,random_split,DataLoader,SubsetRandomSampler\n",
    "from torch.utils.data.dataset import Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.device(cuda)\n",
      "torch.cuda.device_count():  4\n",
      "Tesla V100-SXM2-16GB\n",
      "Tesla V100-SXM2-16GB\n",
      "Tesla V100-SXM2-16GB\n",
      "Tesla V100-SXM2-16GB\n",
      "torch.cuda.current_device() 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"torch.device(cuda)\")\n",
    "    print(\"torch.cuda.device_count(): \", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name())\n",
    "    print(\"torch.cuda.current_device()\", torch.cuda.current_device())\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"torch.device(cpu)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJjxv_T_DNKk"
   },
   "source": [
    "# 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/CTRL_All.npy   Datasets/CTRL_Dapi.npy\r\n",
      "Datasets/CTRL_CTCF.npy  Datasets/CTRL_H3K27ac.npy\r\n"
     ]
    }
   ],
   "source": [
    "ls Datasets/CTRL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/RETT_HPS3042_All.npy      Datasets/RETT_HPS3084_All.npy\r\n",
      "Datasets/RETT_HPS3042_CTCF.npy     Datasets/RETT_HPS3084_CTCF.npy\r\n",
      "Datasets/RETT_HPS3042_Dapi.npy     Datasets/RETT_HPS3084_Dapi.npy\r\n",
      "Datasets/RETT_HPS3042_H3K27ac.npy  Datasets/RETT_HPS3084_H3K27ac.npy\r\n",
      "Datasets/RETT_HPS3049_All.npy      Datasets/RETT_HPS9999_All.npy\r\n",
      "Datasets/RETT_HPS3049_CTCF.npy     Datasets/RETT_HPS9999_CTCF.npy\r\n",
      "Datasets/RETT_HPS3049_Dapi.npy     Datasets/RETT_HPS9999_Dapi.npy\r\n",
      "Datasets/RETT_HPS3049_H3K27ac.npy  Datasets/RETT_HPS9999_H3K27ac.npy\r\n"
     ]
    }
   ],
   "source": [
    "ls Datasets/RETT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stain_type = \"H3K27ac\"\n",
    "rett_type  = \"HPS3042\"\n",
    "\n",
    "X_Ctrl = np.load(f\"./Datasets/CTRL_{stain_type}.npy\",allow_pickle=True)\n",
    "X_Rett = np.load(f\"./Datasets/RETT_{rett_type}_{stain_type}.npy\",allow_pickle=True)\n",
    "y_Ctrl = torch.zeros(len(X_Ctrl), dtype=torch.int64)\n",
    "y_Rett = torch.ones(len(X_Rett), dtype=torch.int64)\n",
    "X = np.concatenate((X_Ctrl, X_Rett), axis = 0)\n",
    "y = torch.cat((y_Ctrl, y_Rett), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyvCoE-HDNKm"
   },
   "source": [
    "# 2. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1627023529885,
     "user": {
      "displayName": "Yicheng Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgziKLn_im8Zl7A_SAzLLRm66nioH7fG0xuCYpJYg=s64",
      "userId": "10487961361854797289"
     },
     "user_tz": -540
    },
    "id": "Fh058iRlDNKm"
   },
   "outputs": [],
   "source": [
    "class cell_dataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transforms.ToTensor()\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.x[idx]).to(torch.float), F.one_hot(self.y[idx],num_classes=2).to(torch.float)\n",
    "\n",
    "dataset = cell_dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_size = int(len(X)*0.8)\n",
    "valid_size = len(X) - train_size\n",
    "\n",
    "# train_data, valid_data = random_split(dataset=dataset, lengths=[train_size, valid_size], \n",
    "#                                       generator=torch.Generator().manual_seed(42))\n",
    "# dataloader_train = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "# dataloader_valid = DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "dataloader_valid = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KBoEbEMDNKo"
   },
   "source": [
    "# 3. ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/groups/4/gaa50089/acd13264yb/Rettsyndrome/Classification/results/HPS3042_H3K27ac_Resnet10_noavg/HPS3042_H3K27ac_Resnet10_noavg_Fold0.pkl\n"
     ]
    }
   ],
   "source": [
    "model_type=\"Resnet10_noavg\"\n",
    "rett_type_test = \"HPS3042\"\n",
    "homepath=\"/groups/4/gaa50089/acd13264yb/Rettsyndrome/Classification\"\n",
    "modelpath=f\"{homepath}/results/{rett_type_test}_{stain_type}_{model_type}/{rett_type_test}_{stain_type}_{model_type}_Fold0.pkl\"\n",
    "weight = torch.load(modelpath)\n",
    "print(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xs6IXgvsDNKp",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if model_type==\"Resnet10_noavg\":\n",
    "    from models.Resnet10 import MyModel\n",
    "elif model_type==\"Resnet10_noavg\":\n",
    "    from models.Resnet10 import MyModel\n",
    "elif model_type==\"Resnet18\":\n",
    "    from models.Resnet18 import MyModel\n",
    "    \n",
    "model = ResNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu = 1\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    model = nn.DataParallel(model, list(range(ngpu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "tensor([[ 13.4811, -11.4782]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.0000e+00, 1.4465e-11]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "image_size = 500\n",
    "test_input = torch.ones(1,3,image_size,image_size).to(device)\n",
    "output = model(test_input)\n",
    "print(output.size())\n",
    "print(output)\n",
    "print(nn.Softmax(dim=1)(output))\n",
    "print(output.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "# loss_function = nn.BCELoss()\n",
    "weights = torch.tensor([(len(X_Ctrl)+len(X_Rett))/len(X_Ctrl), \n",
    "                        (len(X_Ctrl)+len(X_Rett))/len(X_Rett)]).cuda()\n",
    "# loss_function = nn.CrossEntropyLoss(weight=weights)\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "def train(model,device,dataloader_train,loss_function,optimizer):\n",
    "    losses_train = []\n",
    "    n_train = 0\n",
    "    acc_train = 0\n",
    "    optimizer.step()\n",
    "    model.train()\n",
    "    for x, y in dataloader_train:\n",
    "        n_train += y.size()[0]\n",
    "        model.zero_grad()  # 勾配の初期化\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        y = y.to(device)\n",
    "        output = model(x)  # 順伝播\n",
    "        loss = loss_function(output, y)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        loss.backward()  # 誤差の逆伝播\n",
    "        optimizer.step()  # パラメータの更新\n",
    "        acc_train += (output.argmax(1) == y[:,1]).float().sum().item()\n",
    "        losses_train.append(loss.tolist())\n",
    "    return np.mean(losses_train), (acc_train/n_train)\n",
    "        \n",
    "def valid(model,device,dataloader_valid,loss_function):\n",
    "    losses_valid = []\n",
    "    n_val = 0\n",
    "    acc_val = 0\n",
    "    model.eval()\n",
    "    for x, y in dataloader_valid:\n",
    "        n_val += y.size()[0]\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        y = y.to(device)\n",
    "        output = model(x)  # 順伝播\n",
    "        loss = loss_function(output, y)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        acc_val += (output.argmax(1) == y[:,1]).float().sum().item()\n",
    "        losses_valid.append(loss.tolist())\n",
    "    return np.mean(losses_valid), (acc_val/n_val)\n",
    "\n",
    "history = {'loss_train': [], 'loss_valid': [],'acc_train':[],'acc_valid':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_epochs = 10\n",
    "# for epoch in range(n_epochs):\n",
    "#     loss_train, acc_train = train(model,device,dataloader_train,loss_function,optimizer)\n",
    "#     loss_valid, acc_valid = valid(model,device,dataloader_valid,loss_function)\n",
    "#     scheduler.step()\n",
    "    \n",
    "#     history['loss_train'].append(loss_train)\n",
    "#     history['loss_valid'].append(loss_valid)\n",
    "#     history['acc_train'].append(acc_train)\n",
    "#     history['acc_valid'].append(acc_valid)\n",
    "#     print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'\n",
    "#           .format(epoch, loss_train, acc_train, loss_valid, acc_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train processing plot\n",
    "# n_epochs = 50\n",
    "# epochs=range(1,n_epochs+1)\n",
    "# plt.ylim(0,1.0)\n",
    "# plt.plot(epochs, history['acc_train'], 'b', label='Training accuracy')  \n",
    "# plt.plot(epochs, history['acc_valid'], 'r', label='Validation accuracy')\n",
    "# plt.title('Training and Validation accuracy')\n",
    "# plt.legend()\n",
    "# plt.figure()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_roc_curve(y_true, y_scores):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    auc_score = roc_auc_score(y_true, y_scores)\n",
    "    return auc_score\n",
    "\n",
    "def valid(model, device, dataloader_valid):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "    acc_val = 0\n",
    "    n_val = 0\n",
    "    for x, y in dataloader_valid:\n",
    "        n_val += y.size()[0]\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(x)\n",
    "        y_true.extend(y[:,1].tolist())  # 假设y的第二列是标签\n",
    "        y_scores.extend(output[:,1].sigmoid().tolist())  # 假设模型的第二个输出是预测为正类的得分\n",
    "        acc_val += (output.argmax(1) == y[:,1]).float().sum().item()\n",
    "    auc_score = plot_and_save_roc_curve(y_true, y_scores)  # 调用ROC绘图函数\n",
    "    return acc_val / n_val, auc_score\n",
    "\n",
    "def loaddata(stain_type, rett_type):\n",
    "    X_Ctrl = np.load(f\"{homepath}/Datasets_LR/CTRL_{stain_type}.npy\",allow_pickle=True)\n",
    "    X_Rett = np.load(f\"{homepath}/Datasets_LR/RETT_{rett_type}_{stain_type}.npy\",allow_pickle=True)\n",
    "    y_Ctrl = torch.zeros(len(X_Ctrl), dtype=torch.int64)\n",
    "    y_Rett = torch.ones(len(X_Rett), dtype=torch.int64)\n",
    "    X = np.concatenate((X_Ctrl, X_Rett), axis = 0)\n",
    "    y = torch.cat((y_Ctrl, y_Rett), 0)\n",
    "    dataset = cell_dataset(X, y)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All\n",
      "Data HPS3042, Model HPS3042_Fold0  Accuracy: 0.975, AUC: 0.996\n",
      "Data HPS3042, Model HPS3049_Fold0  Accuracy: 0.842, AUC: 0.931\n",
      "Data HPS3042, Model HPS3084_Fold0  Accuracy: 0.911, AUC: 0.979\n",
      "Data HPS3049, Model HPS3042_Fold0  Accuracy: 0.635, AUC: 0.843\n",
      "Data HPS3049, Model HPS3049_Fold0  Accuracy: 0.906, AUC: 0.970\n",
      "Data HPS3049, Model HPS3084_Fold0  Accuracy: 0.676, AUC: 0.849\n",
      "Data HPS3084, Model HPS3042_Fold0  Accuracy: 0.980, AUC: 0.998\n",
      "Data HPS3084, Model HPS3049_Fold0  Accuracy: 0.912, AUC: 0.974\n",
      "Data HPS3084, Model HPS3084_Fold0  Accuracy: 0.987, AUC: 1.000\n",
      "H3K27ac\n",
      "Data HPS3042, Model HPS3042_Fold0  Accuracy: 0.899, AUC: 0.956\n",
      "Data HPS3042, Model HPS3049_Fold0  Accuracy: 0.652, AUC: 0.693\n",
      "Data HPS3042, Model HPS3084_Fold0  Accuracy: 0.899, AUC: 0.964\n",
      "Data HPS3049, Model HPS3042_Fold0  Accuracy: 0.580, AUC: 0.424\n",
      "Data HPS3049, Model HPS3049_Fold0  Accuracy: 0.716, AUC: 0.777\n",
      "Data HPS3049, Model HPS3084_Fold0  Accuracy: 0.572, AUC: 0.425\n",
      "Data HPS3084, Model HPS3042_Fold0  Accuracy: 0.899, AUC: 0.978\n",
      "Data HPS3084, Model HPS3049_Fold0  Accuracy: 0.578, AUC: 0.595\n",
      "Data HPS3084, Model HPS3084_Fold0  Accuracy: 0.890, AUC: 0.959\n",
      "CTCF\n",
      "Data HPS3042, Model HPS3042_Fold0  Accuracy: 0.863, AUC: 0.923\n",
      "Data HPS3042, Model HPS3049_Fold0  Accuracy: 0.652, AUC: 0.639\n",
      "Data HPS3042, Model HPS3084_Fold0  Accuracy: 0.760, AUC: 0.940\n",
      "Data HPS3049, Model HPS3042_Fold0  Accuracy: 0.603, AUC: 0.592\n",
      "Data HPS3049, Model HPS3049_Fold0  Accuracy: 0.770, AUC: 0.835\n",
      "Data HPS3049, Model HPS3084_Fold0  Accuracy: 0.579, AUC: 0.534\n",
      "Data HPS3084, Model HPS3042_Fold0  Accuracy: 0.953, AUC: 0.990\n",
      "Data HPS3084, Model HPS3049_Fold0  Accuracy: 0.643, AUC: 0.700\n",
      "Data HPS3084, Model HPS3084_Fold0  Accuracy: 0.933, AUC: 0.987\n",
      "Dapi\n",
      "Data HPS3042, Model HPS3042_Fold0  Accuracy: 0.793, AUC: 0.820\n",
      "Data HPS3042, Model HPS3049_Fold0  Accuracy: 0.732, AUC: 0.814\n",
      "Data HPS3042, Model HPS3084_Fold0  Accuracy: 0.833, AUC: 0.894\n",
      "Data HPS3049, Model HPS3042_Fold0  Accuracy: 0.634, AUC: 0.646\n",
      "Data HPS3049, Model HPS3049_Fold0  Accuracy: 0.627, AUC: 0.686\n",
      "Data HPS3049, Model HPS3084_Fold0  Accuracy: 0.618, AUC: 0.637\n",
      "Data HPS3084, Model HPS3042_Fold0  Accuracy: 0.741, AUC: 0.815\n",
      "Data HPS3084, Model HPS3049_Fold0  Accuracy: 0.645, AUC: 0.700\n",
      "Data HPS3084, Model HPS3084_Fold0  Accuracy: 0.717, AUC: 0.794\n"
     ]
    }
   ],
   "source": [
    "stain_type = \"H3K27ac\"\n",
    "rett_type  = \"HPS3042\"\n",
    "model_type=\"Resnet10_noavg\"\n",
    "rett_type_model = \"HPS3042\"\n",
    "homepath=\"/groups/4/gaa50089/acd13264yb/Rettsyndrome/Classification\"\n",
    "\n",
    "stain_list = [\"All\", \"H3K27ac\", \"CTCF\", \"Dapi\"]\n",
    "rett_list = [\"HPS3042\", \"HPS3049\", \"HPS3084\"]\n",
    "for stain_type in stain_list:\n",
    "    print(f\"{stain_type}\")\n",
    "\n",
    "    for rett_type in rett_list:\n",
    "        for rett_type_model in rett_list:\n",
    "            dataset = loaddata(stain_type, rett_type)\n",
    "\n",
    "            n_splits=5\n",
    "            splits=KFold(n_splits,shuffle=True,random_state=42)\n",
    "            history = {'acc_valid':[], 'auc_valid':[]}\n",
    "            for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "                if fold != 0: break\n",
    "                print(f\"Data {rett_type}, Model {rett_type_model}_Fold{fold}\", end='  ')\n",
    "                valid_sampler = SubsetRandomSampler(val_idx)\n",
    "                dataloader_valid = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "                modelpath=f\"{homepath}/results_LR/{rett_type_model}_{stain_type}_{model_type}/{rett_type_model}_{stain_type}_{model_type}_Fold{fold}.pkl\"\n",
    "                weight = torch.load(modelpath)\n",
    "\n",
    "                model = ResNet().to(device)\n",
    "                model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "                acc_valid, auc_valid = valid(model, device, dataloader_valid)\n",
    "                print(f'Accuracy: {acc_valid:.3f}, AUC: {auc_valid:.3f}')\n",
    "                history['acc_valid'].append(acc_valid)\n",
    "                history['auc_valid'].append(auc_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m current_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m))\n\u001b[1;32m      2\u001b[0m parent_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(current_dir)\n\u001b[1;32m      3\u001b[0m grandparent_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(parent_dir)\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 99. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "torch.save(model.module.resnet.state_dict(),\"Models/Resnet_H3K27ac.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(ResNet,self).__init__()\n",
    "            self.resnet = models.resnet18(weights=True)\n",
    "            self.resnet.layer3 = nn.Sequential()\n",
    "            self.resnet.layer4 = nn.Sequential()\n",
    "            self.resnet.avgpool = nn.Sequential()\n",
    "            self.resnet.fc = nn.Linear(128*75*75, 2)\n",
    "            self.resnet.load_state_dict(weight)\n",
    "        def forward(self, x):\n",
    "            x = self.resnet(x)\n",
    "            x = nn.Softmax(dim=1)(x)\n",
    "            return x\n",
    "model = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KIMIA_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
