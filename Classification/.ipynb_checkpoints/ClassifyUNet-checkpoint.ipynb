{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score,precision_score,accuracy_score,roc_curve\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,TensorDataset,random_split,DataLoader,SubsetRandomSampler\n",
    "from torch.utils.data.dataset import Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.device(cuda)\n",
      "torch.cuda.device_count():  1\n",
      "Tesla V100-SXM2-16GB\n",
      "torch.cuda.current_device() 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"torch.device(cuda)\")\n",
    "    print(\"torch.cuda.device_count(): \", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name())\n",
    "    print(\"torch.cuda.current_device()\", torch.cuda.current_device())\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"torch.device(cpu)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJjxv_T_DNKk"
   },
   "source": [
    "# 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/CTRL_All.npy   Datasets/CTRL_Dapi.npy\r\n",
      "Datasets/CTRL_CTCF.npy  Datasets/CTRL_H3K27ac.npy\r\n"
     ]
    }
   ],
   "source": [
    "ls Datasets/CTRL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/RETT_HPS3042_All.npy      Datasets/RETT_HPS3084_All.npy\r\n",
      "Datasets/RETT_HPS3042_CTCF.npy     Datasets/RETT_HPS3084_CTCF.npy\r\n",
      "Datasets/RETT_HPS3042_Dapi.npy     Datasets/RETT_HPS3084_Dapi.npy\r\n",
      "Datasets/RETT_HPS3042_H3K27ac.npy  Datasets/RETT_HPS3084_H3K27ac.npy\r\n",
      "Datasets/RETT_HPS3049_All.npy      Datasets/RETT_HPS9999_All.npy\r\n",
      "Datasets/RETT_HPS3049_CTCF.npy     Datasets/RETT_HPS9999_CTCF.npy\r\n",
      "Datasets/RETT_HPS3049_Dapi.npy     Datasets/RETT_HPS9999_Dapi.npy\r\n",
      "Datasets/RETT_HPS3049_H3K27ac.npy  Datasets/RETT_HPS9999_H3K27ac.npy\r\n"
     ]
    }
   ],
   "source": [
    "ls Datasets/RETT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stain_type = \"H3K27ac\"\n",
    "rett_type  = \"HPS3042\"\n",
    "\n",
    "X_Ctrl = np.load(f\"./Datasets/CTRL_{stain_type}.npy\",allow_pickle=True)\n",
    "X_Rett = np.load(f\"./Datasets/RETT_{rett_type}_{stain_type}.npy\",allow_pickle=True)\n",
    "y_Ctrl = torch.zeros(len(X_Ctrl), dtype=torch.int64)\n",
    "y_Rett = torch.ones(len(X_Rett), dtype=torch.int64)\n",
    "X = np.concatenate((X_Ctrl, X_Rett), axis = 0)\n",
    "y = torch.cat((y_Ctrl, y_Rett), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyvCoE-HDNKm"
   },
   "source": [
    "# 2. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1627023529885,
     "user": {
      "displayName": "Yicheng Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgziKLn_im8Zl7A_SAzLLRm66nioH7fG0xuCYpJYg=s64",
      "userId": "10487961361854797289"
     },
     "user_tz": -540
    },
    "id": "Fh058iRlDNKm"
   },
   "outputs": [],
   "source": [
    "class cell_dataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transforms.ToTensor()\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.x[idx]).to(torch.float), F.one_hot(self.y[idx],num_classes=2).to(torch.float)\n",
    "\n",
    "dataset = cell_dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_size = int(len(X)*0.8)\n",
    "valid_size = len(X) - train_size\n",
    "\n",
    "train_data, valid_data = random_split(dataset=dataset, lengths=[train_size, valid_size], \n",
    "                                      generator=torch.Generator().manual_seed(42))\n",
    "dataloader_train = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "dataloader_valid = DataLoader(valid_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KBoEbEMDNKo"
   },
   "source": [
    "# 3. ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type=\"Resnet10_noavg\"\n",
    "# rett_type_test = \"HPS3042\"\n",
    "# homepath=\"/groups/4/gaa50089/acd13264yb/Rettsyndrome/Classification\"\n",
    "# modelpath=f\"{homepath}/results/{rett_type_test}_{stain_type}_{model_type}/{rett_type_test}_{stain_type}_{model_type}_Fold0.pkl\"\n",
    "# weight = torch.load(modelpath)\n",
    "# print(modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "    \n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "        self.down_sample = nn.MaxPool2d(2)\n",
    "    def forward(self, x):\n",
    "        skip_out = self.double_conv(x)\n",
    "        down_out = self.down_sample(skip_out)\n",
    "        return (down_out, skip_out)\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UpBlock, self).__init__()\n",
    "#         self.up_sample = nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2)\n",
    "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "    def forward(self, down_input, skip_input):\n",
    "        skip_shape = skip_input.shape\n",
    "        x = F.interpolate(down_input, size=[skip_shape[2],skip_shape[3]],mode='nearest-exact')\n",
    "        x = torch.cat([x, skip_input], dim=1)\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        # Downsampling Path\n",
    "        self.down_conv1 = DownBlock(3, 64)\n",
    "        self.down_conv2 = DownBlock(64, 128)\n",
    "        self.down_conv3 = DownBlock(128, 256)\n",
    "        self.down_conv4 = DownBlock(256, 512)\n",
    "        # Bottleneck\n",
    "        self.double_conv = DoubleConv(512, 1024)\n",
    "        # Upsampling Path\n",
    "        self.up_conv4 = UpBlock(512 + 1024, 512)\n",
    "        self.up_conv3 = UpBlock(256 + 512, 256)\n",
    "        self.up_conv2 = UpBlock(128 + 256, 128)\n",
    "        self.up_conv1 = UpBlock(64 + 128, 64)\n",
    "        # output\n",
    "        self.output = nn.Conv2d(64,1,kernel_size=1)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_image):\n",
    "        x, skip1_out = self.down_conv1(input_image)\n",
    "        print(f\"x.size {x.size()} skip1_out.size {skip1_out.size()}\")\n",
    "        x, skip2_out = self.down_conv2(x)\n",
    "        print(f\"x.size {x.size()} skip1_out.size {skip1_out.size()}\")\n",
    "        x, skip3_out = self.down_conv3(x)\n",
    "        print(f\"x.size {x.size()} skip1_out.size {skip1_out.size()}\")\n",
    "        x, skip4_out = self.down_conv4(x)\n",
    "        print(f\"x.size {x.size()} skip1_out.size {skip1_out.size()}\")\n",
    "        x = self.double_conv(x)\n",
    "        print(f\"x.size {x.size()}\")\n",
    "        x = self.up_conv4(x, skip4_out)\n",
    "        print(f\"x.size {x.size()} skip1_out.size {skip1_out.size()}\")\n",
    "        x = self.up_conv3(x, skip3_out)\n",
    "        print(f\"x.size {x.size()} skip1_out.size {skip1_out.size()}\")\n",
    "        x = self.up_conv2(x, skip2_out)\n",
    "        print(f\"x.size {x.size()} skip1_out.size {skip1_out.size()}\")\n",
    "        x = self.up_conv1(x, skip1_out)\n",
    "        print(f\"x.size {x.size()} skip1_out.size {skip1_out.size()}\")\n",
    "        x = self.output(x)\n",
    "        print(f\"x.size {x.size()}\")\n",
    "#         x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class maskUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(maskUNet, self).__init__()\n",
    "        self.UNetblock = UNet()  # 确保 UNet 已经定义\n",
    "        self.fc = nn.Linear(500 * 500, 2)  # 假设UNet输出大小是500x500，全连接层输出为两个类别\n",
    "\n",
    "    def forward(self, input_image):\n",
    "        # UNet 处理\n",
    "        mask = self.UNetblock(input_image)\n",
    "        \n",
    "        # 展平操作\n",
    "        output = torch.flatten(mask, start_dim=1)  # 保持batch维度不变，展平其他维度\n",
    "        \n",
    "        # 全连接层\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return mask, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = maskUNet().to(device)\n",
    "# model = nn.DataParallel(model, list(range(ngpu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size torch.Size([1, 64, 250, 250]) skip1_out.size torch.Size([1, 64, 500, 500])\n",
      "x.size torch.Size([1, 128, 125, 125]) skip1_out.size torch.Size([1, 64, 500, 500])\n",
      "x.size torch.Size([1, 256, 62, 62]) skip1_out.size torch.Size([1, 64, 500, 500])\n",
      "x.size torch.Size([1, 512, 31, 31]) skip1_out.size torch.Size([1, 64, 500, 500])\n",
      "x.size torch.Size([1, 1024, 31, 31])\n",
      "x.size torch.Size([1, 512, 62, 62]) skip1_out.size torch.Size([1, 64, 500, 500])\n",
      "x.size torch.Size([1, 256, 125, 125]) skip1_out.size torch.Size([1, 64, 500, 500])\n",
      "x.size torch.Size([1, 128, 250, 250]) skip1_out.size torch.Size([1, 64, 500, 500])\n",
      "x.size torch.Size([1, 64, 500, 500]) skip1_out.size torch.Size([1, 64, 500, 500])\n",
      "x.size torch.Size([1, 1, 500, 500])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 1, 500, 500])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14e7414dd600>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_size = 500\n",
    "test_input = torch.ones(1,3,image_size,image_size).to(device)\n",
    "mask, output = model(test_input)\n",
    "print(output.size())\n",
    "print(mask.size())\n",
    "plt.imshow(mask[0,0,:,:].cpu().detach().numpy())\n",
    "# print(nn.Softmax(dim=1)(output))\n",
    "# print(output.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "# loss_function = nn.BCELoss()\n",
    "weights = torch.tensor([(len(X_Ctrl)+len(X_Rett))/len(X_Ctrl), \n",
    "                        (len(X_Ctrl)+len(X_Rett))/len(X_Rett)]).cuda()\n",
    "# loss_function = nn.CrossEntropyLoss(weight=weights)\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "def train(model,device,dataloader_train,loss_function,optimizer):\n",
    "    losses_train = []\n",
    "    n_train = 0\n",
    "    acc_train = 0\n",
    "    optimizer.step()\n",
    "    model.train()\n",
    "    for x, y in dataloader_train:\n",
    "        n_train += y.size()[0]\n",
    "        model.zero_grad()  # 勾配の初期化\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        y = y.to(device)\n",
    "        output = model(x)  # 順伝播\n",
    "        loss = loss_function(output, y)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        loss.backward()  # 誤差の逆伝播\n",
    "        optimizer.step()  # パラメータの更新\n",
    "        acc_train += (output.argmax(1) == y[:,1]).float().sum().item()\n",
    "        losses_train.append(loss.tolist())\n",
    "    return np.mean(losses_train), (acc_train/n_train)\n",
    "        \n",
    "def valid(model,device,dataloader_valid,loss_function):\n",
    "    losses_valid = []\n",
    "    n_val = 0\n",
    "    acc_val = 0\n",
    "    model.eval()\n",
    "    for x, y in dataloader_valid:\n",
    "        n_val += y.size()[0]\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        y = y.to(device)\n",
    "        output = model(x)  # 順伝播\n",
    "        loss = loss_function(output, y)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        acc_val += (output.argmax(1) == y[:,1]).float().sum().item()\n",
    "        losses_valid.append(loss.tolist())\n",
    "    return np.mean(losses_valid), (acc_val/n_val)\n",
    "\n",
    "history = {'loss_train': [], 'loss_valid': [],'acc_train':[],'acc_valid':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.82 GiB (GPU 0; 15.77 GiB total capacity; 13.10 GiB already allocated; 1.38 GiB free; 13.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m----> 3\u001b[0m     loss_train, acc_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     loss_valid, acc_valid \u001b[38;5;241m=\u001b[39m valid(model,device,dataloader_valid,loss_function)\n\u001b[1;32m      5\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, dataloader_train, loss_function, optimizer)\u001b[0m\n\u001b[1;32m     21\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# テンソルをGPUに移動\u001b[39;00m\n\u001b[1;32m     22\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 23\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 順伝播\u001b[39;00m\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(output, y)  \u001b[38;5;66;03m# 誤差(クロスエントロピー誤差関数)の計算\u001b[39;00m\n\u001b[1;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# 誤差の逆伝播\u001b[39;00m\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mmaskUNet.forward\u001b[0;34m(self, input_image)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_image):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# UNet 处理\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUNetblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# 展平操作\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(mask, start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 保持batch维度不变，展平其他维度\u001b[39;00m\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, input_image)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_image):\n\u001b[0;32m---> 21\u001b[0m     x, skip1_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown_conv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx.size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m skip1_out.size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mskip1_out\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m     x, skip2_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_conv2(x)\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mDownBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 22\u001b[0m     skip_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     down_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_sample(skip_out)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (down_out, skip_out)\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mDoubleConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.82 GiB (GPU 0; 15.77 GiB total capacity; 13.10 GiB already allocated; 1.38 GiB free; 13.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    loss_train, acc_train = train(model,device,dataloader_train,loss_function,optimizer)\n",
    "    loss_valid, acc_valid = valid(model,device,dataloader_valid,loss_function)\n",
    "    scheduler.step()\n",
    "    \n",
    "    history['loss_train'].append(loss_train)\n",
    "    history['loss_valid'].append(loss_valid)\n",
    "    history['acc_train'].append(acc_train)\n",
    "    history['acc_valid'].append(acc_valid)\n",
    "    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'\n",
    "          .format(epoch, loss_train, acc_train, loss_valid, acc_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train processing plot\n",
    "n_epochs = 50\n",
    "epochs=range(1,n_epochs+1)\n",
    "plt.ylim(0,1.0)\n",
    "plt.plot(epochs, history['acc_train'], 'b', label='Training accuracy')  \n",
    "plt.plot(epochs, history['acc_valid'], 'r', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_roc_curve(y_true, y_scores, fold):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    auc_score = roc_auc_score(y_true, y_scores)\n",
    "    return auc_score\n",
    "\n",
    "def valid(model, device, dataloader_valid):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "    acc_val = 0\n",
    "    n_val = 0\n",
    "    for x, y in dataloader_valid:\n",
    "        n_val += y.size()[0]\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(x)\n",
    "        y_true.extend(y[:,1].tolist())  # 假设y的第二列是标签\n",
    "        y_scores.extend(output[:,1].sigmoid().tolist())  # 假设模型的第二个输出是预测为正类的得分\n",
    "        acc_val += (output.argmax(1) == y[:,1]).float().sum().item()\n",
    "    auc_score = plot_and_save_roc_curve(y_true, y_scores, fold)  # 调用ROC绘图函数\n",
    "    return acc_val / n_val, auc_score\n",
    "\n",
    "def loaddata(stain_type, rett_type):\n",
    "    X_Ctrl = np.load(f\"{homepath}/Datasets/CTRL_{stain_type}.npy\",allow_pickle=True)\n",
    "    X_Rett = np.load(f\"{homepath}/Datasets/RETT_{rett_type}_{stain_type}.npy\",allow_pickle=True)\n",
    "    y_Ctrl = torch.zeros(len(X_Ctrl), dtype=torch.int64)\n",
    "    y_Rett = torch.ones(len(X_Rett), dtype=torch.int64)\n",
    "    X = np.concatenate((X_Ctrl, X_Rett), axis = 0)\n",
    "    y = torch.cat((y_Ctrl, y_Rett), 0)\n",
    "    dataset = cell_dataset(X, y)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All\n",
      "🔶 Data HPS3042, 🔷 Model HPS3042  Accuracy: 0.994, AUC: 1.000\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3049  Accuracy: 0.748, AUC: 0.888\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3084  Accuracy: 0.911, AUC: 0.990\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3042  Accuracy: 0.599, AUC: 0.833\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3049  Accuracy: 0.985, AUC: 0.999\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3084  Accuracy: 0.624, AUC: 0.871\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3042  Accuracy: 0.988, AUC: 1.000\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3049  Accuracy: 0.798, AUC: 0.960\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3084  Accuracy: 0.999, AUC: 1.000\n",
      "\n",
      "H3K27ac\n",
      "🔶 Data HPS3042, 🔷 Model HPS3042  Accuracy: 0.981, AUC: 0.999\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3049  Accuracy: 0.657, AUC: 0.481\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3084  Accuracy: 0.929, AUC: 0.985\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3042  Accuracy: 0.565, AUC: 0.477\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3049  Accuracy: 0.953, AUC: 0.992\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3084  Accuracy: 0.559, AUC: 0.501\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3042  Accuracy: 0.894, AUC: 0.985\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3049  Accuracy: 0.583, AUC: 0.499\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3084  Accuracy: 0.978, AUC: 0.998\n",
      "\n",
      "CTCF\n",
      "🔶 Data HPS3042, 🔷 Model HPS3042  Accuracy: 0.982, AUC: 0.998\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3049  Accuracy: 0.712, AUC: 0.768\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3084  Accuracy: 0.853, AUC: 0.975\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3042  Accuracy: 0.626, AUC: 0.653\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3049  Accuracy: 0.958, AUC: 0.993\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3084  Accuracy: 0.575, AUC: 0.585\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3042  Accuracy: 0.985, AUC: 0.999\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3049  Accuracy: 0.719, AUC: 0.837\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3084  Accuracy: 0.996, AUC: 1.000\n",
      "\n",
      "Dapi\n",
      "🔶 Data HPS3042, 🔷 Model HPS3042  Accuracy: 0.959, AUC: 0.989\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3049  Accuracy: 0.743, AUC: 0.858\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3084  Accuracy: 0.854, AUC: 0.937\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3042  Accuracy: 0.630, AUC: 0.757\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3049  Accuracy: 0.942, AUC: 0.986\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3084  Accuracy: 0.643, AUC: 0.799\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3042  Accuracy: 0.762, AUC: 0.872\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3049  Accuracy: 0.668, AUC: 0.791\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3084  Accuracy: 0.940, AUC: 0.988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# whole data\n",
    "# stain_type = \"H3K27ac\"\n",
    "# rett_type  = \"HPS3042\"\n",
    "# rett_type_model = \"HPS3042\"\n",
    "model_type=\"Resnet10_noavg\"\n",
    "homepath=\"/groups/4/gaa50089/acd13264yb/Rettsyndrome/Classification\"\n",
    "\n",
    "stain_list = [\"All\", \"H3K27ac\", \"CTCF\", \"Dapi\"]\n",
    "rett_list = [\"HPS3042\", \"HPS3049\", \"HPS3084\"]\n",
    "for stain_type in stain_list:\n",
    "    print(f\"{stain_type}\")\n",
    "\n",
    "    for rett_type in rett_list:\n",
    "        for rett_type_model in rett_list:\n",
    "            dataset = loaddata(stain_type, rett_type)\n",
    "\n",
    "            history = {'acc_valid':[], 'auc_valid':[]}\n",
    "            print(f\"Data {rett_type}, Model {rett_type_model}\", end='  ')\n",
    "\n",
    "            dataloader_valid = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "            modelpath=f\"{homepath}/results/{rett_type_model}_{stain_type}_{model_type}/{rett_type_model}_{stain_type}_{model_type}_Fold0.pkl\"\n",
    "            weight = torch.load(modelpath)\n",
    "\n",
    "            model = ResNet().to(device)\n",
    "            model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "            acc_valid, auc_valid = valid(model, device, dataloader_valid)\n",
    "            print(f'Accuracy: {acc_valid:.3f}, AUC: {auc_valid:.3f}')\n",
    "            history['acc_valid'].append(acc_valid)\n",
    "            history['auc_valid'].append(auc_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All\n",
      "Data HPS3042, Model HPS3042_Fold0  Accuracy: 0.971, AUC: 0.998\n",
      "Data HPS3042, Model HPS3049_Fold0  Accuracy: 0.726, AUC: 0.848\n",
      "Data HPS3042, Model HPS3084_Fold0  Accuracy: 0.914, AUC: 0.987\n",
      "Data HPS3049, Model HPS3042_Fold0  Accuracy: 0.611, AUC: 0.812\n",
      "Data HPS3049, Model HPS3049_Fold0  Accuracy: 0.925, AUC: 0.977\n",
      "Data HPS3049, Model HPS3084_Fold0  Accuracy: 0.645, AUC: 0.855\n",
      "Data HPS3084, Model HPS3042_Fold0  Accuracy: 0.985, AUC: 0.999\n",
      "Data HPS3084, Model HPS3049_Fold0  Accuracy: 0.810, AUC: 0.927\n",
      "Data HPS3084, Model HPS3084_Fold0  Accuracy: 0.993, AUC: 1.000\n",
      "H3K27ac\n",
      "Data HPS3042, Model HPS3042_Fold0  Accuracy: 0.907, AUC: 0.975\n",
      "Data HPS3042, Model HPS3049_Fold0  Accuracy: 0.622, AUC: 0.434\n",
      "Data HPS3042, Model HPS3084_Fold0  Accuracy: 0.905, AUC: 0.967\n",
      "Data HPS3049, Model HPS3042_Fold0  Accuracy: 0.575, AUC: 0.405\n",
      "Data HPS3049, Model HPS3049_Fold0  Accuracy: 0.765, AUC: 0.858\n",
      "Data HPS3049, Model HPS3084_Fold0  Accuracy: 0.548, AUC: 0.366\n",
      "Data HPS3084, Model HPS3042_Fold0  Accuracy: 0.887, AUC: 0.979\n",
      "Data HPS3084, Model HPS3049_Fold0  Accuracy: 0.522, AUC: 0.398\n",
      "Data HPS3084, Model HPS3084_Fold0  Accuracy: 0.890, AUC: 0.961\n",
      "CTCF\n",
      "Data HPS3042, Model HPS3042_Fold0  Accuracy: 0.913, AUC: 0.976\n",
      "Data HPS3042, Model HPS3049_Fold0  Accuracy: 0.681, AUC: 0.687\n",
      "Data HPS3042, Model HPS3084_Fold0  Accuracy: 0.861, AUC: 0.974\n",
      "Data HPS3049, Model HPS3042_Fold0  Accuracy: 0.621, AUC: 0.598\n",
      "Data HPS3049, Model HPS3049_Fold0  Accuracy: 0.793, AUC: 0.869\n",
      "Data HPS3049, Model HPS3084_Fold0  Accuracy: 0.590, AUC: 0.529\n",
      "Data HPS3084, Model HPS3042_Fold0  Accuracy: 0.975, AUC: 0.999\n",
      "Data HPS3084, Model HPS3049_Fold0  Accuracy: 0.678, AUC: 0.744\n",
      "Data HPS3084, Model HPS3084_Fold0  Accuracy: 0.982, AUC: 0.997\n",
      "Dapi\n",
      "Data HPS3042, Model HPS3042_Fold0  Accuracy: 0.795, AUC: 0.852\n",
      "Data HPS3042, Model HPS3049_Fold0  Accuracy: 0.677, AUC: 0.742\n",
      "Data HPS3042, Model HPS3084_Fold0  Accuracy: 0.819, AUC: 0.890\n",
      "Data HPS3049, Model HPS3042_Fold0  Accuracy: 0.621, AUC: 0.659\n",
      "Data HPS3049, Model HPS3049_Fold0  Accuracy: 0.710, AUC: 0.786\n",
      "Data HPS3049, Model HPS3084_Fold0  Accuracy: 0.588, AUC: 0.609\n",
      "Data HPS3084, Model HPS3042_Fold0  Accuracy: 0.751, AUC: 0.810\n",
      "Data HPS3084, Model HPS3049_Fold0  Accuracy: 0.597, AUC: 0.610\n",
      "Data HPS3084, Model HPS3084_Fold0  Accuracy: 0.700, AUC: 0.769\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold\n",
    "stain_type = \"H3K27ac\"\n",
    "rett_type  = \"HPS3042\"\n",
    "model_type=\"Resnet10_noavg\"\n",
    "rett_type_model = \"HPS3042\"\n",
    "homepath=\"/groups/4/gaa50089/acd13264yb/Rettsyndrome/Classification\"\n",
    "\n",
    "stain_list = [\"All\", \"H3K27ac\", \"CTCF\", \"Dapi\"]\n",
    "rett_list = [\"HPS3042\", \"HPS3049\", \"HPS3084\"]\n",
    "for stain_type in stain_list:\n",
    "    print(f\"{stain_type}\")\n",
    "\n",
    "    for rett_type in rett_list:\n",
    "        for rett_type_model in rett_list:\n",
    "            dataset = loaddata(stain_type, rett_type)\n",
    "\n",
    "            n_splits=5\n",
    "            splits=KFold(n_splits,shuffle=True,random_state=42)\n",
    "            history = {'acc_valid':[], 'auc_valid':[]}\n",
    "            for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "                if fold != 0: break\n",
    "                print(f\"Data {rett_type}, Model {rett_type_model}_Fold{fold}\", end='  ')\n",
    "                valid_sampler = SubsetRandomSampler(val_idx)\n",
    "                dataloader_valid = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "                modelpath=f\"{homepath}/results/{rett_type_model}_{stain_type}_{model_type}/{rett_type_model}_{stain_type}_{model_type}_Fold{fold}.pkl\"\n",
    "                weight = torch.load(modelpath)\n",
    "\n",
    "                model = ResNet().to(device)\n",
    "                model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "                acc_valid, auc_valid = valid(model, device, dataloader_valid)\n",
    "                print(f'Accuracy: {acc_valid:.3f}, AUC: {auc_valid:.3f}')\n",
    "                history['acc_valid'].append(acc_valid)\n",
    "                history['auc_valid'].append(auc_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 99. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "torch.save(model.module.resnet.state_dict(),\"Models/Resnet_H3K27ac.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(ResNet,self).__init__()\n",
    "            self.resnet = models.resnet18(weights=True)\n",
    "            self.resnet.layer3 = nn.Sequential()\n",
    "            self.resnet.layer4 = nn.Sequential()\n",
    "            self.resnet.avgpool = nn.Sequential()\n",
    "            self.resnet.fc = nn.Linear(128*75*75, 2)\n",
    "            self.resnet.load_state_dict(weight)\n",
    "        def forward(self, x):\n",
    "            x = self.resnet(x)\n",
    "            x = nn.Softmax(dim=1)(x)\n",
    "            return x\n",
    "model = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KIMIA_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
