{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score,precision_score,accuracy_score,roc_curve\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,TensorDataset,random_split,DataLoader,SubsetRandomSampler\n",
    "from torch.utils.data.dataset import Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.device(cuda)\n",
      "torch.cuda.device_count():  4\n",
      "Tesla V100-SXM2-16GB\n",
      "Tesla V100-SXM2-16GB\n",
      "Tesla V100-SXM2-16GB\n",
      "Tesla V100-SXM2-16GB\n",
      "torch.cuda.current_device() 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"torch.device(cuda)\")\n",
    "    print(\"torch.cuda.device_count(): \", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name())\n",
    "    print(\"torch.cuda.current_device()\", torch.cuda.current_device())\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"torch.device(cpu)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJjxv_T_DNKk"
   },
   "source": [
    "# 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/CTRL_All.npy   Datasets/CTRL_Dapi.npy\r\n",
      "Datasets/CTRL_CTCF.npy  Datasets/CTRL_H3K27ac.npy\r\n"
     ]
    }
   ],
   "source": [
    "ls Datasets/CTRL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/RETT_HPS3042_All.npy      Datasets/RETT_HPS3084_All.npy\r\n",
      "Datasets/RETT_HPS3042_CTCF.npy     Datasets/RETT_HPS3084_CTCF.npy\r\n",
      "Datasets/RETT_HPS3042_Dapi.npy     Datasets/RETT_HPS3084_Dapi.npy\r\n",
      "Datasets/RETT_HPS3042_H3K27ac.npy  Datasets/RETT_HPS3084_H3K27ac.npy\r\n",
      "Datasets/RETT_HPS3049_All.npy      Datasets/RETT_HPS9999_All.npy\r\n",
      "Datasets/RETT_HPS3049_CTCF.npy     Datasets/RETT_HPS9999_CTCF.npy\r\n",
      "Datasets/RETT_HPS3049_Dapi.npy     Datasets/RETT_HPS9999_Dapi.npy\r\n",
      "Datasets/RETT_HPS3049_H3K27ac.npy  Datasets/RETT_HPS9999_H3K27ac.npy\r\n"
     ]
    }
   ],
   "source": [
    "ls Datasets/RETT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stain_type = \"H3K27ac\"\n",
    "rett_type  = \"HPS3042\"\n",
    "\n",
    "X_Ctrl = np.load(f\"./Datasets/CTRL_{stain_type}.npy\",allow_pickle=True)\n",
    "X_Rett = np.load(f\"./Datasets/RETT_{rett_type}_{stain_type}.npy\",allow_pickle=True)\n",
    "y_Ctrl = torch.zeros(len(X_Ctrl), dtype=torch.int64)\n",
    "y_Rett = torch.ones(len(X_Rett), dtype=torch.int64)\n",
    "X = np.concatenate((X_Ctrl, X_Rett), axis = 0)\n",
    "y = torch.cat((y_Ctrl, y_Rett), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyvCoE-HDNKm"
   },
   "source": [
    "# 2. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1627023529885,
     "user": {
      "displayName": "Yicheng Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgziKLn_im8Zl7A_SAzLLRm66nioH7fG0xuCYpJYg=s64",
      "userId": "10487961361854797289"
     },
     "user_tz": -540
    },
    "id": "Fh058iRlDNKm"
   },
   "outputs": [],
   "source": [
    "class cell_dataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transforms.ToTensor()\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.x[idx]).to(torch.float), F.one_hot(self.y[idx],num_classes=2).to(torch.float)\n",
    "\n",
    "dataset = cell_dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_size = int(len(X)*0.8)\n",
    "valid_size = len(X) - train_size\n",
    "\n",
    "# train_data, valid_data = random_split(dataset=dataset, lengths=[train_size, valid_size], \n",
    "#                                       generator=torch.Generator().manual_seed(42))\n",
    "# dataloader_train = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "# dataloader_valid = DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "dataloader_valid = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KBoEbEMDNKo"
   },
   "source": [
    "# 3. ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m homepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/groups/4/gaa50089/acd13264yb/Rettsyndrome/Classification\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m modelpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhomepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrett_type_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstain_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrett_type_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstain_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Fold0.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(modelpath)\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/serialization.py:1116\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1112\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39mUntypedStorage)\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1116\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1117\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1121\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 217\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/serialization.py:187\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(obj\u001b[38;5;241m.\u001b[39mnbytes(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(location))\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python10_env/lib/python3.10/site-packages/torch/_utils.py:81\u001b[0m, in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_type(indices, values, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     untyped_storage \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     untyped_storage\u001b[38;5;241m.\u001b[39mcopy_(\u001b[38;5;28mself\u001b[39m, non_blocking)\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model_type=\"Resnet10_noavg\"\n",
    "rett_type_test = \"HPS3042\"\n",
    "homepath=\"/groups/4/gaa50089/acd13264yb/Rettsyndrome/Classification\"\n",
    "modelpath=f\"{homepath}/results/{rett_type_test}_{stain_type}_{model_type}/{rett_type_test}_{stain_type}_{model_type}_Fold0.pkl\"\n",
    "weight = torch.load(modelpath)\n",
    "print(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xs6IXgvsDNKp",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if model_type==\"Resnet10_noavg\":\n",
    "    class ResNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(ResNet,self).__init__()\n",
    "            self.resnet = models.resnet18(weights=True)\n",
    "            self.resnet.layer3 = nn.Sequential()\n",
    "            self.resnet.layer4 = nn.Sequential()\n",
    "            self.resnet.avgpool = nn.Sequential()\n",
    "            self.resnet.fc = nn.Linear(128*63*63, 2)\n",
    "            if model_type!=None: \n",
    "                self.resnet.load_state_dict(weight)\n",
    "        def forward(self, x):\n",
    "            x = self.resnet(x)\n",
    "#             x = nn.Softmax(dim=1)(x)\n",
    "            return x\n",
    "elif model_type==\"Resnet10\":\n",
    "    class ResNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(ResNet,self).__init__()\n",
    "            self.resnet = models.resnet18(weights=True)\n",
    "            self.resnet.layer3 = nn.Sequential()\n",
    "            self.resnet.layer4 = nn.Sequential()\n",
    "            self.resnet.fc = nn.Linear(128, 2)\n",
    "            if model_type!=None: \n",
    "                self.resnet.load_state_dict(weight)\n",
    "        def forward(self, x):\n",
    "            x = self.resnet(x)\n",
    "#             x = nn.Softmax(dim=1)(x)\n",
    "            return x\n",
    "elif model_type==\"Resnet18\":\n",
    "    class ResNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(ResNet,self).__init__()\n",
    "            self.resnet = models.resnet18(weights=True)\n",
    "            self.resnet.fc = nn.Linear(512, 2)\n",
    "            if model_type!=None: \n",
    "                self.resnet.load_state_dict(weight)\n",
    "        def forward(self, x):\n",
    "            x = self.resnet(x)\n",
    "#             x = nn.Softmax(dim=1)(x)\n",
    "            return x\n",
    "    \n",
    "model = ResNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu = 1\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    model = nn.DataParallel(model, list(range(ngpu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m image_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[0;32m----> 2\u001b[0m test_input \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m model(test_input)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "image_size = 500\n",
    "test_input = torch.ones(1,3,image_size,image_size).to(device)\n",
    "output = model(test_input)\n",
    "print(output.size())\n",
    "print(output)\n",
    "print(nn.Softmax(dim=1)(output))\n",
    "print(output.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "# loss_function = nn.BCELoss()\n",
    "weights = torch.tensor([(len(X_Ctrl)+len(X_Rett))/len(X_Ctrl), \n",
    "                        (len(X_Ctrl)+len(X_Rett))/len(X_Rett)]).cuda()\n",
    "# loss_function = nn.CrossEntropyLoss(weight=weights)\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "def train(model,device,dataloader_train,loss_function,optimizer):\n",
    "    losses_train = []\n",
    "    n_train = 0\n",
    "    acc_train = 0\n",
    "    optimizer.step()\n",
    "    model.train()\n",
    "    for x, y in dataloader_train:\n",
    "        n_train += y.size()[0]\n",
    "        model.zero_grad()  # 勾配の初期化\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        y = y.to(device)\n",
    "        output = model(x)  # 順伝播\n",
    "        loss = loss_function(output, y)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        loss.backward()  # 誤差の逆伝播\n",
    "        optimizer.step()  # パラメータの更新\n",
    "        acc_train += (output.argmax(1) == y[:,1]).float().sum().item()\n",
    "        losses_train.append(loss.tolist())\n",
    "    return np.mean(losses_train), (acc_train/n_train)\n",
    "        \n",
    "def valid(model,device,dataloader_valid,loss_function):\n",
    "    losses_valid = []\n",
    "    n_val = 0\n",
    "    acc_val = 0\n",
    "    model.eval()\n",
    "    for x, y in dataloader_valid:\n",
    "        n_val += y.size()[0]\n",
    "        x = x.to(device)  # テンソルをGPUに移動\n",
    "        y = y.to(device)\n",
    "        output = model(x)  # 順伝播\n",
    "        loss = loss_function(output, y)  # 誤差(クロスエントロピー誤差関数)の計算\n",
    "        acc_val += (output.argmax(1) == y[:,1]).float().sum().item()\n",
    "        losses_valid.append(loss.tolist())\n",
    "    return np.mean(losses_valid), (acc_val/n_val)\n",
    "\n",
    "history = {'loss_train': [], 'loss_valid': [],'acc_train':[],'acc_valid':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0, Train [Loss: 0.005, Accuracy: 1.000], Valid [Loss: 1.325, Accuracy: 0.737]\n",
      "EPOCH: 1, Train [Loss: 0.003, Accuracy: 1.000], Valid [Loss: 1.230, Accuracy: 0.756]\n",
      "EPOCH: 2, Train [Loss: 0.003, Accuracy: 1.000], Valid [Loss: 1.276, Accuracy: 0.750]\n",
      "EPOCH: 3, Train [Loss: 0.003, Accuracy: 1.000], Valid [Loss: 1.271, Accuracy: 0.745]\n",
      "EPOCH: 4, Train [Loss: 0.003, Accuracy: 1.000], Valid [Loss: 1.308, Accuracy: 0.752]\n",
      "EPOCH: 5, Train [Loss: 0.003, Accuracy: 1.000], Valid [Loss: 1.180, Accuracy: 0.752]\n",
      "EPOCH: 6, Train [Loss: 0.003, Accuracy: 1.000], Valid [Loss: 1.207, Accuracy: 0.755]\n",
      "EPOCH: 7, Train [Loss: 0.002, Accuracy: 1.000], Valid [Loss: 1.295, Accuracy: 0.752]\n",
      "EPOCH: 8, Train [Loss: 0.002, Accuracy: 1.000], Valid [Loss: 1.427, Accuracy: 0.742]\n",
      "EPOCH: 9, Train [Loss: 0.002, Accuracy: 1.000], Valid [Loss: 1.229, Accuracy: 0.757]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    loss_train, acc_train = train(model,device,dataloader_train,loss_function,optimizer)\n",
    "    loss_valid, acc_valid = valid(model,device,dataloader_valid,loss_function)\n",
    "    scheduler.step()\n",
    "    \n",
    "    history['loss_train'].append(loss_train)\n",
    "    history['loss_valid'].append(loss_valid)\n",
    "    history['acc_train'].append(acc_train)\n",
    "    history['acc_valid'].append(acc_valid)\n",
    "    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'\n",
    "          .format(epoch, loss_train, acc_train, loss_valid, acc_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train processing plot\n",
    "n_epochs = 50\n",
    "epochs=range(1,n_epochs+1)\n",
    "plt.ylim(0,1.0)\n",
    "plt.plot(epochs, history['acc_train'], 'b', label='Training accuracy')  \n",
    "plt.plot(epochs, history['acc_valid'], 'r', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_roc_curve(y_true, y_scores, fold):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    auc_score = roc_auc_score(y_true, y_scores)\n",
    "    return auc_score\n",
    "\n",
    "def valid(model, device, dataloader_valid):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "    acc_val = 0\n",
    "    n_val = 0\n",
    "    for x, y in dataloader_valid:\n",
    "        n_val += y.size()[0]\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(x)\n",
    "        y_true.extend(y[:,1].tolist())  # 假设y的第二列是标签\n",
    "        y_scores.extend(output[:,1].sigmoid().tolist())  # 假设模型的第二个输出是预测为正类的得分\n",
    "        acc_val += (output.argmax(1) == y[:,1]).float().sum().item()\n",
    "    auc_score = plot_and_save_roc_curve(y_true, y_scores, fold)  # 调用ROC绘图函数\n",
    "    return acc_val / n_val, auc_score\n",
    "\n",
    "def loaddata(stain_type, rett_type):\n",
    "    X_Ctrl = np.load(f\"{homepath}/Datasets/CTRL_{stain_type}.npy\",allow_pickle=True)\n",
    "    X_Rett = np.load(f\"{homepath}/Datasets/RETT_{rett_type}_{stain_type}.npy\",allow_pickle=True)\n",
    "    y_Ctrl = torch.zeros(len(X_Ctrl), dtype=torch.int64)\n",
    "    y_Rett = torch.ones(len(X_Rett), dtype=torch.int64)\n",
    "    X = np.concatenate((X_Ctrl, X_Rett), axis = 0)\n",
    "    y = torch.cat((y_Ctrl, y_Rett), 0)\n",
    "    dataset = cell_dataset(X, y)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All\n",
      "🔶 Data HPS3042, 🔷 Model HPS3042  Accuracy: 0.994, AUC: 1.000\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3049  Accuracy: 0.748, AUC: 0.888\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3084  Accuracy: 0.911, AUC: 0.990\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3042  Accuracy: 0.599, AUC: 0.833\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3049  Accuracy: 0.985, AUC: 0.999\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3084  Accuracy: 0.624, AUC: 0.871\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3042  Accuracy: 0.988, AUC: 1.000\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3049  Accuracy: 0.798, AUC: 0.960\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3084  Accuracy: 0.999, AUC: 1.000\n",
      "\n",
      "H3K27ac\n",
      "🔶 Data HPS3042, 🔷 Model HPS3042  Accuracy: 0.981, AUC: 0.999\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3049  Accuracy: 0.657, AUC: 0.481\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3084  Accuracy: 0.929, AUC: 0.985\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3042  Accuracy: 0.565, AUC: 0.477\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3049  Accuracy: 0.953, AUC: 0.992\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3084  Accuracy: 0.559, AUC: 0.501\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3042  Accuracy: 0.894, AUC: 0.985\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3049  Accuracy: 0.583, AUC: 0.499\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3084  Accuracy: 0.978, AUC: 0.998\n",
      "\n",
      "CTCF\n",
      "🔶 Data HPS3042, 🔷 Model HPS3042  Accuracy: 0.982, AUC: 0.998\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3049  Accuracy: 0.712, AUC: 0.768\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3084  Accuracy: 0.853, AUC: 0.975\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3042  Accuracy: 0.626, AUC: 0.653\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3049  Accuracy: 0.958, AUC: 0.993\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3084  Accuracy: 0.575, AUC: 0.585\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3042  Accuracy: 0.985, AUC: 0.999\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3049  Accuracy: 0.719, AUC: 0.837\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3084  Accuracy: 0.996, AUC: 1.000\n",
      "\n",
      "Dapi\n",
      "🔶 Data HPS3042, 🔷 Model HPS3042  Accuracy: 0.959, AUC: 0.989\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3049  Accuracy: 0.743, AUC: 0.858\n",
      "\n",
      "🔶 Data HPS3042, 🔷 Model HPS3084  Accuracy: 0.854, AUC: 0.937\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3042  Accuracy: 0.630, AUC: 0.757\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3049  Accuracy: 0.942, AUC: 0.986\n",
      "\n",
      "🔶 Data HPS3049, 🔷 Model HPS3084  Accuracy: 0.643, AUC: 0.799\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3042  Accuracy: 0.762, AUC: 0.872\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3049  Accuracy: 0.668, AUC: 0.791\n",
      "\n",
      "🔶 Data HPS3084, 🔷 Model HPS3084  Accuracy: 0.940, AUC: 0.988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# whole data\n",
    "# stain_type = \"H3K27ac\"\n",
    "# rett_type  = \"HPS3042\"\n",
    "# rett_type_model = \"HPS3042\"\n",
    "model_type=\"Resnet10_noavg\"\n",
    "homepath=\"/groups/4/gaa50089/acd13264yb/Rettsyndrome/Classification\"\n",
    "\n",
    "stain_list = [\"All\", \"H3K27ac\", \"CTCF\", \"Dapi\"]\n",
    "rett_list = [\"HPS3042\", \"HPS3049\", \"HPS3084\"]\n",
    "for stain_type in stain_list:\n",
    "    print(f\"{stain_type}\")\n",
    "\n",
    "    for rett_type in rett_list:\n",
    "        for rett_type_model in rett_list:\n",
    "            dataset = loaddata(stain_type, rett_type)\n",
    "\n",
    "            history = {'acc_valid':[], 'auc_valid':[]}\n",
    "            print(f\"Data {rett_type}, Model {rett_type_model}\", end='  ')\n",
    "\n",
    "            dataloader_valid = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "            modelpath=f\"{homepath}/results/{rett_type_model}_{stain_type}_{model_type}/{rett_type_model}_{stain_type}_{model_type}_Fold0.pkl\"\n",
    "            weight = torch.load(modelpath)\n",
    "\n",
    "            model = ResNet().to(device)\n",
    "            model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "            acc_valid, auc_valid = valid(model, device, dataloader_valid)\n",
    "            print(f'Accuracy: {acc_valid:.3f}, AUC: {auc_valid:.3f}')\n",
    "            history['acc_valid'].append(acc_valid)\n",
    "            history['auc_valid'].append(auc_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All\n",
      "Data HPS3042, Model HPS3042_Fold0  Accuracy: 0.971, AUC: 0.998\n",
      "Data HPS3042, Model HPS3049_Fold0  Accuracy: 0.726, AUC: 0.848\n",
      "Data HPS3042, Model HPS3084_Fold0  Accuracy: 0.914, AUC: 0.987\n",
      "Data HPS3049, Model HPS3042_Fold0  Accuracy: 0.611, AUC: 0.812\n",
      "Data HPS3049, Model HPS3049_Fold0  Accuracy: 0.925, AUC: 0.977\n",
      "Data HPS3049, Model HPS3084_Fold0  Accuracy: 0.645, AUC: 0.855\n",
      "Data HPS3084, Model HPS3042_Fold0  Accuracy: 0.985, AUC: 0.999\n",
      "Data HPS3084, Model HPS3049_Fold0  Accuracy: 0.810, AUC: 0.927\n",
      "Data HPS3084, Model HPS3084_Fold0  Accuracy: 0.993, AUC: 1.000\n",
      "H3K27ac\n",
      "Data HPS3042, Model HPS3042_Fold0  Accuracy: 0.907, AUC: 0.975\n",
      "Data HPS3042, Model HPS3049_Fold0  Accuracy: 0.622, AUC: 0.434\n",
      "Data HPS3042, Model HPS3084_Fold0  Accuracy: 0.905, AUC: 0.967\n",
      "Data HPS3049, Model HPS3042_Fold0  Accuracy: 0.575, AUC: 0.405\n",
      "Data HPS3049, Model HPS3049_Fold0  Accuracy: 0.765, AUC: 0.858\n",
      "Data HPS3049, Model HPS3084_Fold0  Accuracy: 0.548, AUC: 0.366\n",
      "Data HPS3084, Model HPS3042_Fold0  Accuracy: 0.887, AUC: 0.979\n",
      "Data HPS3084, Model HPS3049_Fold0  Accuracy: 0.522, AUC: 0.398\n",
      "Data HPS3084, Model HPS3084_Fold0  Accuracy: 0.890, AUC: 0.961\n",
      "CTCF\n",
      "Data HPS3042, Model HPS3042_Fold0  Accuracy: 0.913, AUC: 0.976\n",
      "Data HPS3042, Model HPS3049_Fold0  Accuracy: 0.681, AUC: 0.687\n",
      "Data HPS3042, Model HPS3084_Fold0  Accuracy: 0.861, AUC: 0.974\n",
      "Data HPS3049, Model HPS3042_Fold0  Accuracy: 0.621, AUC: 0.598\n",
      "Data HPS3049, Model HPS3049_Fold0  Accuracy: 0.793, AUC: 0.869\n",
      "Data HPS3049, Model HPS3084_Fold0  Accuracy: 0.590, AUC: 0.529\n",
      "Data HPS3084, Model HPS3042_Fold0  Accuracy: 0.975, AUC: 0.999\n",
      "Data HPS3084, Model HPS3049_Fold0  Accuracy: 0.678, AUC: 0.744\n",
      "Data HPS3084, Model HPS3084_Fold0  Accuracy: 0.982, AUC: 0.997\n",
      "Dapi\n",
      "Data HPS3042, Model HPS3042_Fold0  Accuracy: 0.795, AUC: 0.852\n",
      "Data HPS3042, Model HPS3049_Fold0  Accuracy: 0.677, AUC: 0.742\n",
      "Data HPS3042, Model HPS3084_Fold0  Accuracy: 0.819, AUC: 0.890\n",
      "Data HPS3049, Model HPS3042_Fold0  Accuracy: 0.621, AUC: 0.659\n",
      "Data HPS3049, Model HPS3049_Fold0  Accuracy: 0.710, AUC: 0.786\n",
      "Data HPS3049, Model HPS3084_Fold0  Accuracy: 0.588, AUC: 0.609\n",
      "Data HPS3084, Model HPS3042_Fold0  Accuracy: 0.751, AUC: 0.810\n",
      "Data HPS3084, Model HPS3049_Fold0  Accuracy: 0.597, AUC: 0.610\n",
      "Data HPS3084, Model HPS3084_Fold0  Accuracy: 0.700, AUC: 0.769\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold\n",
    "stain_type = \"H3K27ac\"\n",
    "rett_type  = \"HPS3042\"\n",
    "model_type=\"Resnet10_noavg\"\n",
    "rett_type_model = \"HPS3042\"\n",
    "homepath=\"/groups/4/gaa50089/acd13264yb/Rettsyndrome/Classification\"\n",
    "\n",
    "stain_list = [\"All\", \"H3K27ac\", \"CTCF\", \"Dapi\"]\n",
    "rett_list = [\"HPS3042\", \"HPS3049\", \"HPS3084\"]\n",
    "for stain_type in stain_list:\n",
    "    print(f\"{stain_type}\")\n",
    "\n",
    "    for rett_type in rett_list:\n",
    "        for rett_type_model in rett_list:\n",
    "            dataset = loaddata(stain_type, rett_type)\n",
    "\n",
    "            n_splits=5\n",
    "            splits=KFold(n_splits,shuffle=True,random_state=42)\n",
    "            history = {'acc_valid':[], 'auc_valid':[]}\n",
    "            for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "                if fold != 0: break\n",
    "                print(f\"Data {rett_type}, Model {rett_type_model}_Fold{fold}\", end='  ')\n",
    "                valid_sampler = SubsetRandomSampler(val_idx)\n",
    "                dataloader_valid = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "                modelpath=f\"{homepath}/results/{rett_type_model}_{stain_type}_{model_type}/{rett_type_model}_{stain_type}_{model_type}_Fold{fold}.pkl\"\n",
    "                weight = torch.load(modelpath)\n",
    "\n",
    "                model = ResNet().to(device)\n",
    "                model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "                acc_valid, auc_valid = valid(model, device, dataloader_valid)\n",
    "                print(f'Accuracy: {acc_valid:.3f}, AUC: {auc_valid:.3f}')\n",
    "                history['acc_valid'].append(acc_valid)\n",
    "                history['auc_valid'].append(auc_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 99. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "torch.save(model.module.resnet.state_dict(),\"Models/Resnet_H3K27ac.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(ResNet,self).__init__()\n",
    "            self.resnet = models.resnet18(weights=True)\n",
    "            self.resnet.layer3 = nn.Sequential()\n",
    "            self.resnet.layer4 = nn.Sequential()\n",
    "            self.resnet.avgpool = nn.Sequential()\n",
    "            self.resnet.fc = nn.Linear(128*75*75, 2)\n",
    "            self.resnet.load_state_dict(weight)\n",
    "        def forward(self, x):\n",
    "            x = self.resnet(x)\n",
    "            x = nn.Softmax(dim=1)(x)\n",
    "            return x\n",
    "model = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KIMIA_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
